{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,  roc_auc_score\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'A', 'alpha', 'ascii_124', 'b', 'beta', 'C', 'cos', 'd', 'Delta', 'div', 'e', 'exists', 'f', 'forall', 'forward_slash', 'G', 'gamma', 'geq', 'gt', 'H', 'i', 'in', 'infty', 'int', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'M', 'mu', 'N', 'neq', 'o', 'p', 'phi', 'pi', 'pm', 'prime', 'q', 'R', 'rightarrow', 'S', 'sigma', 'sin', 'sqrt', 'sum', 'T', 'tan', 'theta', 'times', 'u', 'v', 'w', 'X', 'y', 'z', '[', ']', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "folders=os.listdir( '245_data')\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "alphabet_data=['A', 'b','C','d', 'e', 'f', 'G', 'H', 'i', 'j', 'k', 'l', 'M','N','o', 'p','q', 'R','S','T', 'u', 'v', 'w', 'X', 'y', 'z']\n",
    "symbol_data=['!', '(', ')', '+', ',', '-','=','alpha', 'ascii_124', 'beta', 'cos', 'Delta', 'div','exists', 'forall', 'forward_slash','gamma', 'geq', 'gt', 'in', 'infty', 'int','lambda', 'ldots', 'leq', 'lim', 'log', 'lt','mu', 'neq', 'phi', 'pi', 'pm', 'prime', 'rightarrow', 'sigma', 'sin', 'sqrt', 'sum', 'tan', 'theta', 'times', '[', ']', '{', '}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6         7         8    9  ...       247  \\\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.403922  1.000000  1.0  ...  0.415686   \n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.000000  0.403922  1.0  ...  0.000000   \n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.403922  1.000000  1.0  ...  0.415686   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.000000  0.403922  1.0  ...  0.588235   \n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.996078  0.592157  1.0  ...  0.592157   \n",
       "\n",
       "   248  249  250  251  252  253  254  255  label  \n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0      !  \n",
       "1  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0      !  \n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0      !  \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0      !  \n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0      !  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "\n",
    "for each in folders:\n",
    "    file_ct=0\n",
    "    currentFolder = 'C:/Users/Yunao/Downloads/245_data/' + each\n",
    "    for i, file in enumerate(os.listdir(currentFolder)):\n",
    "        if file_ct > 1000:\n",
    "                break\n",
    "        im= cv2.imread((os.path.join(currentFolder, file)))\n",
    "        img=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        #resize\n",
    "        resized_image = cv2.resize(img, (16,16))\n",
    "        #normalization\n",
    "        img = np.array(resized_image)/255\n",
    "        \n",
    "        img = img.ravel()\n",
    "        img = img.tolist()\n",
    "        \n",
    "        data.append(img)\n",
    "        label.append(each)\n",
    "            \n",
    "        file_ct+=1\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "df[\"label\"] = label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67640, 257)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label Distribution')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEXCAYAAABRWhj0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9B0lEQVR4nO3deVwV9f748dfZOICgLIEgei03KDXwqhVmuKSiIKLo1RbTrKxMrdRrGW43u+aSaZbZTfNrN+vaxQUxQ9TSTEVLqV9KadpNUcgAlVU8cJb5/XFkEkQdTRb1/Xw8fMh75jOfeZ85c+Y9yzkzOkVRFIQQQggN9LWdgBBCiBuHFA0hhBCaSdEQQgihmRQNIYQQmknREEIIoZkUDSGEEJpJ0RA3tMzMTNq1a3fV0wUHB3PmzJmrmmbSpEksW7bsouHvvPMO9913H7GxscTGxhIdHc348eM5duyY2iY2NpbCwsJL9l1UVMSwYcMuOb58+rVr1/LMM89cVd4AixYt4osvvgBg4cKFrFu37qr7EALAWNsJCHEziIqKYtq0aWq8bt06hg8fzueff46HhwdJSUmXnb6goIADBw5ccvyVpr+Sb775hhYtWgDwwgsv/Km+xK1Nioa4aR09epQZM2Zw9uxZcnNzCQkJ4a233sJsNgPw1ltvceDAARwOBy+++CLdunUDYNWqVaxcuRKHw4GXlxdTp06lefPmVzXv/v37s379ej777DMefvhhgoOD2b17N3a7nZdffpm8vDwAunTpwosvvsgrr7yCxWIhNjaWtWvXEhoayoMPPsihQ4eYN28egwYNYvfu3QDk5uby5JNPkpOTQ1BQEK+99hp+fn489thjPProo/Tu3RtAjU+fPk16ejpz587FYDDw5Zdf0rJlS5588kn27dvH3LlzOXfuHCaTiRdffJGIiAjWrl3Lli1b0Ov1ZGRk4Orqypw5c656OYibj5yeEjethIQE+vfvT0JCAps3byYzM5OvvvpKHd+4cWMSExN54403mDRpEmfOnOHbb79l3bp1fPLJJ6xbt46nnnqKMWPGXNP8g4ODOXz48EU5lc/3k08+ISMjg6KiImbNmoWrqytJSUkYDAasVivdunVj06ZNtG3btkIfR48eZdq0aXz22We0atWKmTNnXjaPRx99lDZt2vDSSy/Rs2dPdXheXh7PP/88kydP5rPPPmPOnDlMnDiREydOALB3716mTp3Khg0bCA0NZcmSJde0HMTNRY40xE1r4sSJ7Nq1i6VLl3Ls2DFycnIoKSlRxz/88MMAtGrViubNm/P999+TlpZGRkYGDz30kNqusLCQ/Pz8q56/TqfD1dW1wrAHHniAp59+mpMnT9KpUycmTJiAp6cnBQUFF03foUOHKvvt1KkTTZs2BWDQoEEMGjToqnMD2L9/P3/5y18IDQ0FoGXLlvz1r3/l22+/RafT0bp1awICAgC466672LJlyzXNR9xcpGiIm9b48eOx2+306dOHrl27cvLkSS681Zpe/8eBtsPhwGg04nA4iI2NZeLEierwnJwcGjRocNXzP3DgAAMHDqww7O677+bLL79k9+7d7Nmzh7/97W8sXboULy+vi6Z3d3evsl+DwXBR3uUufH1Wq/Wy+dntdnQ6XYVhiqJgs9kwmUwVCp5Op0NuUydATk+Jm9jOnTsZPXo0UVFRAPzwww/Y7XZ1fGJiIgA//vgjx48fJzQ0lM6dO/P555+Tk5MDwMqVKxk+fPhVz3vVqlVkZmbSp0+fCsPnzZvH4sWL6dGjB5MnT6ZFixYcOXIEo9GI3W7XtGH+5ptv+O233wD49NNPiYiIAMDHx4f09HQAfvnlF37++Wd1GoPBgM1mq9BPWFgYv/76K/v37wfgyJEj7N27l3vuueeqX6+4dciRhrjhlZSUXPS1208//ZRx48YxevRo3N3d8fDwoGPHjhw/flxtc+LECfr3749Op2P+/Pl4eXnRuXNnRo4cyRNPPIFOp8PDw4NFixZdtEdeWXJyMmlpaeh0OhwOB3fccQcfffSRetG93PDhw5k0aRJ9+/bFxcWF4OBgoqOjMRgM3H333URHR/PJJ59cdl6tWrUiPj6eU6dO0axZM2bMmAHAqFGjmDRpEtu3b6dZs2YVTm91796d+fPnVzj68PHxYeHChbz22mtYLBZ0Oh2zZs3ijjvu4Pvvv7/8Qhe3LJ3cGl0IIYRWcnpKCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmUjSEEEJodtP/TiMv7ywOh3yrWAghtNDrdXh717vk+Ju+aDgcihQNIYS4TuT0lBBCCM2kaAghhNBMioYQQgjNpGgIIYTQrFqLRnFxMX379iUzMxOA1NRUYmJi6NWrFwsWLFDbHTx4kLi4OCIjI5k8ebJ6C+fffvtNfXzlqFGjOHv2bHWmK4QQ4gqqrWj88MMPPPzwwxw7dgwAi8VCfHw8ixcvJjk5mfT0dLZv3w44n7A2bdo0Nm3ahKIoJCQkAPDqq6/yyCOPkJKSQps2bVi8eHF1pSuEEEKDaisaCQkJTJ8+HX9/f8D5aMmmTZvSpEkTjEYjMTExpKSkkJWVhcViISwsDIC4uDhSUlKwWq3s3buXyMjICsOFEELUnmr7nUblh93n5OTg5+enxv7+/mRnZ1803M/Pj+zsbPLy8vDw8FAfZVk+/Gr5NHBDZ3Q+HlOx2QEF3fk+lfOnwa4uVtAZTedj6/nxF8YKOqPL+bgMBdCfjwEctlL0RvNl4jK4YJqqYgUwnI/t58dfz1jRgdHgjG125/jyGMBmK8V4Qc4XxZWmqSq+sL+qWO1lmM63ufDvcmX2MlzOD7vw70sps1txMZguGWtRZrfhYjCqfwMV4vK/L91eh8v5R7WWnX+C4NXELhc85lV7zvar6rPM7sDFoL/ob63jK7PaFUwG3UV/l7PZFYwXDKscV8VuVzCcb2O3O3+DdTWxoVL/DpuC3qhT/wY0xwAOq4Le9EesWB3oTPpLxzYHADqj/pJx+d8XTnO59s7tzh/bufK/q0ON/bjP4XBUePqZoijqU86qGl7+/4Wu9PS0quiMBnLf+xgAv1FDAcj91/8542efOB//63z8LAA5/3Jeb/F/dhwAv7/nLIABoyYDcHLxKwAEPjcLgKxFzumCxjj7yXi7PwBNn1+HDvj53Vg1n+DRSRx4r58atx21nrR/xahx+2c/A2D3kr4AhD+9AYCvl0YDEDHycwC+/MAZP/iUM05Z5nykae8nkwH47P+cjxmNeWIjAGuX9wYgboTzaO2/5+Mh5+OPP3Qe0Q19fBMAH/67FwCPD98MwNKPItUcRw7bxOKP/4ifG7qJhZ/8Eb/wqLOPN1Y6h0182BnP/K8znjxkE7m5RVyOn58nTyc6c1wyIOWi9n5+nvRJegSAjbH/0dRfVOI0NU4eMOOK01TVR/TaRQB8HjcGgOg1zvf884HPVplj3zXLAdgwcAQAfVd/5IwHDTsff3I+fvR8/On5+KHz8arz8d+uOt/yHGJXO9/DpEHO97T/6q0ArBvUvcqc49bsBmDtwPAqx/9tzQEAVg1sq2m5/z3ReU1z3oDGVfa3MPF3NX5hQICmPtesPgXAwEG3AbAhwRn3HeyMN690xr0edsZffZILQNdH/arMYd//OR/v2+EJ55mRH5Y649CRzvjge84d1jtHNQTg17f/yLnZ8wFkzvsjbvz3AE7OPaHGgS814fd5/1PjgL83B+D3+Qed8fg7Ache8AMADceFVplj9kLn+9LwhXBn+7d3OOPnHwAg5x3n++o/9uL39Wro9Tp8fT0uPf6ae75KAQEB5ObmqnFubi7+/v4XDT916hT+/v74+PhQVFSkPtO5vL0QQojaU2NFIzQ0lKNHj5KRkYHdbmfDhg1EREQQFBSE2WwmLS0NgKSkJCIiIjCZTHTo0IHkZOee87p164iIiKipdIUQQlShxk5Pmc1mZs+ezdixYyktLaVLly707u08/TBv3jymTJlCcXExrVu3Ztgw56H79OnTmTRpEu+99x6BgYHMnz+/ptIVQghRhWovGlu3blX/Dg8PZ/369Re1CQkJYfXq1RcNDwoKYsWKFdWanxBCCO1u+rvcCnGr8PRyw9X0x0faYrXVYjbiZiVFQ4ibhKvJSOzqZDVOGhRVi9mIm5Xce0oIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmUjSEEEJoZqztBIQAqO/lgtlkBqDUWlrL2QghLkWKhqgTzCYzE1b3BuDNQSm1nI0Q4lLk9JQQQgjNpGgIIYTQTIqGEEIIzaRoCCGE0EyKhhBCCM2kaAghhNBMioYQQgjNpGgIIYTQrFaKRlJSEtHR0URHRzNnzhwAUlNTiYmJoVevXixYsEBte/DgQeLi4oiMjGTy5MnYbLbaSFkIIQS1UDTOnTvHzJkzWbFiBUlJSezbt4+tW7cSHx/P4sWLSU5OJj09ne3btwMwceJEpk2bxqZNm1AUhYSEhJpOWQghxHk1XjTsdjsOh4Nz585hs9mw2Wx4eHjQtGlTmjRpgtFoJCYmhpSUFLKysrBYLISFhQEQFxdHSorcYkIIIWpLjd97ysPDgxdeeIE+ffrg5uZGx44dycnJwc/PT23j7+9Pdnb2RcP9/PzIzs6u6ZSFEDXEZlfw8/NU4zKrg4L8s7WYkaisxovGoUOHWLNmDdu2bcPT05O///3vHDt2DJ1Op7ZRFAWdTofD4ahyuLjxXbhhuB7tr7a/a52mJvurif7/7HK93u+j0aBj6docNR4Z53/DvU/Xw5/NsTpfY40XjZ07dxIeHo6vry/gPOW0bNkyDAaD2iY3Nxd/f38CAgLIzc1Vh586dQp/f/+aTllUg9zcogrxlVbyK7WvPL6yqvq/0jRa+rhcf9f7g3str/Fq+7zScv2zy/1altH1Xq7V/T5dD382x6tdty+k1+vw9fW49Phr7vkahYSEkJqaSklJCYqisHXrVkJDQzl69CgZGRnY7XY2bNhAREQEQUFBmM1m0tLSAOe3riIiImo6ZSGEEOfV+JFG586d+emnn4iLi8NkMtG2bVvGjh3L/fffz9ixYyktLaVLly707u18tsK8efOYMmUKxcXFtG7dmmHDhtV0ykIIIc6rlYcwPf300zz99NMVhoWHh7N+/fqL2oaEhLB69eqaSk0IIW54Pg3cMLg4N+/2Mudv2y6MzxScu+a+5cl9QghxkzG4GMlZtAkA/zGRAOQs+vx8HP2n+pbbiAghhNBMioYQQgjNpGgIIYTQTIqGEEIIzaRoCCGE0EyKhhBCCM2kaAghhNBMioYQQgjNpGgIIYTQTIqGEEIIzaRoCCGE0EyKhhBCCM2kaAghhNBMioYQQgjNpGgIIYTQTIqGEEIIzeQhTEIAnl6uuJpMamyxWinKt9RiRkLUTVI0hABcTSaiE99Q488HTKQIKRpCVCanp4QQQmgmRUMIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmtVI0tm7dSlxcHH369OGf//wnAKmpqcTExNCrVy8WLFigtj148CBxcXFERkYyefJkbDZbbaQshBCCWigaJ06cYPr06SxevJj169fz008/sX37duLj41m8eDHJycmkp6ezfft2ACZOnMi0adPYtGkTiqKQkJBQ0ykLUSd5ernh5+ep/hOiJtR40diyZQtRUVEEBARgMplYsGABbm5uNG3alCZNmmA0GomJiSElJYWsrCwsFgthYWEAxMXFkZKSUtMpC1EnuZqM9Fu9Xv0nRE2o8Sf3ZWRkYDKZePbZZzl58iRdu3alZcuW+Pn5qW38/f3Jzs4mJyenwnA/Pz+ys7NrOmVRDa52z/hK7a9lT/t691nde/vV0f+fXQY1sYyu9+u+EY7K6vK6VONFw263s2/fPlasWIG7uzujRo3C1dUVnU6ntlEUBZ1Oh8PhqHK4uPHl5hZViK+0El+pfeXxlVXV/4XTXGn89cjxz6qO/q92uf7Z5X4tr+F6v+7qfp+uh5pely6k1+vw9fW45PgaLxq33XYb4eHh+Pj4ANCjRw9SUlIwGAxqm9zcXPz9/QkICCA3N1cdfurUKfz9/Ws6ZSGEEOdpuqZR1SmhX3755Zpm2K1bN3bu3ElhYSF2u50dO3bQu3dvjh49SkZGBna7nQ0bNhAREUFQUBBms5m0tDQAkpKSiIiIuKb5CiGE+PMue6SRn58PwMiRI1mxYgWKogBgs9kYM2bMNV2UDg0N5amnnuKRRx7BarVy//338/DDD9OsWTPGjh1LaWkpXbp0oXfv3gDMmzePKVOmUFxcTOvWrRk2bNhVz1MIIcT1cdmiMWHCBHbt2gXAvffe+8dERiORkZHXPNNBgwYxaNCgCsPCw8NZv/7ib4CEhISwevXqa56XEEKI6+eyRWPZsmUAvPLKK8yaNatGEhJCCFF3aboQPmvWLLKysigoKFBPUQG0bt262hITQghR92gqGm+//TbLli3D19dXHabT6fjyyy+rLTEhhBB1j6aisW7dOjZv3kzDhg2rOx8hxA3E08sdV5Pz6/IWq52i/JJazujm4NPAHYOLc7nay+y1nE1FmopGYGCgFAwhxEVcTQYGrzkMQMLAVlz+p35CK4OLgey39gHQ8MUOtZxNRZqKRnh4OHPnzuXBBx/E1dVVHS7XNIQQ4taiqWisXbsWoMLvMuSahhBC3Ho0FY2tW7dWdx5CCCFuAJqKxvLly6scPmLEiOuajBBCiLpNU9E4fPiw+ndZWRl79+4lPDy82pISQghRN2n+cd+FsrOzmTx5crUkJIQQou66pif3NWzYkKysrOudixBCiDruqq9pKIpCenp6hV+HCyGEuDVc9TUNcP7Y76WXXqqWhIQQQtRdV3VNIysrC5vNRtOmTas1KSGEEHWTpqKRkZHBc889R05ODg6HA29vb95//32aN29e3fkJIYSoQzRdCJ8xYwZPPfUUe/fuJS0tjVGjRvHqq69Wd25CCCHqGE1F4/Tp0wwYMECNBw4cSF5eXrUlJYQQom7SVDTsdrv6vHCAM2fOVFc+Qggh6jBN1zSGDh3KkCFD6NOnDzqdjuTkZIYPH17duQkhhKhjNB1pdOnSBQCr1cr//vc/srOz6dmzZ7UmJoSofp5ebvj5eeLn54mnl1ttpyNuAJqONCZNmsSjjz7KsGHDKC0tZeXKlcTHx7N06dLqzk8IUY1cTUYGrNkBQOLAB2o5G3Ej0HSkkZeXx7BhwwAwm808/vjj5ObmVmtiQggh6h7NF8Kzs7PV+NSpUyiKUm1JCSGEqJs0nZ56/PHH6d+/Pw888AA6nY7U1FS5jYgQQtyCNBWNQYMG0aZNG/bs2YPBYODJJ5+kVatW1Z2bEOIG4+nljqvJAIDFaq/lbER10FQ0AEJCQggJCanOXIQQNzhXk4FhazMA+ChO7lF3M7qm52kIIYS4NUnREEIIoZkUDSGEEJpJ0RBCCKGZFA0hhBCa1WrRmDNnDpMmTQIgNTWVmJgYevXqxYIFC9Q2Bw8eJC4ujsjISCZPnozNZqutdIUQ4pZXa0Vj9+7dJCYmAmCxWIiPj2fx4sUkJyeTnp7O9u3bAZg4cSLTpk1j06ZNKIpCQkJCbaUshBC3vFopGvn5+SxYsIBnn30WgP3799O0aVOaNGmC0WgkJiaGlJQUsrKysFgshIWFARAXF0dKSkptpCxuMmV2m3p3Vz8/z9pOR4gbhuYf911P06ZNY9y4cZw8eRKAnJwc/Pz81PH+/v5kZ2dfNNzPz6/CPbCEuFYuBiNRiTPVOHnA5FrMRogbR40XjVWrVhEYGEh4eDhr164FwOFwoNPp1DaKoqDT6S45XNz4rnbv/krtq+No4Xrn+GfVxhHR9Z7ntfRXF3K42fyZZVDjRSM5OZnc3FxiY2MpKCigpKSErKwsDAaD2iY3Nxd/f38CAgIq3IL91KlT+Pv713TKohrk5hZViK+0El+pfeXxlV3Lh+R65/hnVXf/NTHPa+mvLuRws7nc50Wv1+Hr63HJ8TVeNJYvX67+vXbtWr799lteffVVevXqRUZGBo0bN2bDhg0MHDiQoKAgzGYzaWlptG/fnqSkJCIiImo6ZSGEEOfVyjWNysxmM7Nnz2bs2LGUlpbSpUsXevfuDcC8efOYMmUKxcXFtG7dWn0YlBBCiJpXq0UjLi6OuLg4AMLDw1m/fv1FbUJCQli9enVNpyaEEDctnwZuGFz+2PwrNhs6o7ZyUCeONIQQQtQcg4uRnHfXqbH/6P7kLF4FgN7Tndsei77ktHIbESGEEJpJ0RBCCKGZFA0hhBCayTUNIUSNaeDljovJcOWGos6SoiGEqDEuJgP/TDypxlMGBNZiNuJayOkpIYQQmknREEIIoZkUDSGEEJrJNQ0hRJ3m5VUPk8m5f2u1Omo5GyFFQwhRp5lMej5Z67zb9aNxfldoLaqbnJ4SQgihmRQNIYQQmknREEIIoZkUDSGEEJpJ0RBCCKGZFA0hhBCaSdEQQgihmRQNIYQQmknREEIIoZkUDSGEEJpJ0RBCCKGZFA0hhBCaSdEQQgihmdzlVohL8PRyxdVkAsBitdZyNkLUDVI0hLgEV5OJ6LULAPg8blwtZyNE3SCnp4QQQmgmRUMIIYRmUjSEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGa1UjQWLVpEdHQ00dHRzJ07F4DU1FRiYmLo1asXCxYsUNsePHiQuLg4IiMjmTx5MjabrTZSFkIIQS0UjdTUVHbu3EliYiLr1q3jxx9/ZMOGDcTHx7N48WKSk5NJT09n+/btAEycOJFp06axadMmFEUhISGhplMWQghxXo0XDT8/PyZNmoSLiwsmk4nmzZtz7NgxmjZtSpMmTTAajcTExJCSkkJWVhYWi4WwsDAA4uLiSElJqemUhRBCnFfjRaNly5ZqETh27BgbN25Ep9Ph5+entvH39yc7O5ucnJwKw/38/MjOzq7plIUQQpxXa7cROXLkCM888wwvvfQSBoOBY8eOqeMURUGn0+FwONDpdBcNFzc+Pz/P69q+8vgyuxUXg0n9uyZc7Wuqa/3XlXlWN18fD/QG53bEYVdqOZsbT60UjbS0NJ5//nni4+OJjo7m22+/JTc3Vx2fm5uLv78/AQEBFYafOnUKf3//2khZXGe5uUUV4ittnK7UvqrxUeteAiC5/9xrTfOqXO1rqmv915V5Vje9QUfqR87tSqdhfldoLSqr8dNTJ0+eZPTo0cybN4/o6GgAQkNDOXr0KBkZGdjtdjZs2EBERARBQUGYzWbS0tIASEpKIiIioqZTFkIIcV6NH2ksW7aM0tJSZs+erQ576KGHmD17NmPHjqW0tJQuXbrQu3dvAObNm8eUKVMoLi6mdevWDBs2rKZTFkIIcV6NF40pU6YwZcqUKsetX7/+omEhISGsXr26utMSQgihgTxPQwhxSZ5e7riaDABYrPZazkbUBVI0hBCX5GoyMGiN85ri6oHtazkbURfIvaeEEEJoJkVDCCGEZlI0hBBCaCZFQwghhGZSNIQQQmgmRUMIIYRm8pVbUSvqe7lgNpkBKLWW1nI2QgitpGiIWmE2mZm6ynmrmNf+Js9IEeJGIaenhBBCaCZFQwghhGZSNIQQQmgmRUMIIYRmciFciBuEp5cbrib5yIraJWugEDcIV5ORmNWJavzZoAG1mI24VcnpKSGEEJpJ0RBCCKGZFA0hhBCaSdEQQgihmRQNIYQQmknREEIIoZkUDSGEEJpJ0RBCCKGZFA0hhBCaSdEQQgihmRQNIYQQmsm9p8RNwdPLjKvJBQCLtayWcnDF1WQ6n4O1VnIQorpJ0RA3BVeTC32SngNgY+ziWsrBRPSapQB8PnBkreQgRHWT01NCCCE0k6IhhBBCMykaQgghNJNrGuKG4OnlgqvJDIDFWlrL2Qhx67ohjjQ+++wzoqKi6NWrF5988kltpyNqgavJzMCk3gxM6q0WDyFEzavzRxrZ2dksWLCAtWvX4uLiwkMPPcS9995LixYtajs1IYS45dT5opGamsp9992Hl5cXAJGRkaSkpDBmzBjNfeg961WKPSrFnpXi+hVig2eDSrFXpdi3UuxfITZWik2VYpdKMYDZw/+ysWul2O0KsbtHw8vG9SrFHvUuH3teIQaoX2lYA/eKsVel2LtS7Fsp9nOrGPu73VYp9qkYu3tXir0qxQ0qxRXf96qG+bt7XiH2uEJc7ypj9yvEbpeNncNcLxv7uZuvELtUik2V4oqbkdvcDRVi70pxg0qxZ6XYw/3iEyD1Kg1zrxS7VYpd610+NleKXTwqxqbKsWfF2OhZMWdD/SvFF29qDfUrLkf9RXHF5a73NF8hdr1C7FYpdq8y1te7eB26kE5RFOWyLWrZ+++/T0lJCePGjQNg1apV7N+/n9dee62WMxNCiFtPnb+m4XA40Ol0aqwoSoVYCCFEzanzRSMgIIDc3Fw1zs3Nxd//4tM5Qgghql+dLxqdOnVi9+7dnDlzhnPnzrF582YiIiJqOy0hhLgl1fkL4Q0bNmTcuHEMGzYMq9XKoEGDuPvuu2s7LSGEuCXV+QvhQggh6o46f3pKCCFE3SFFQwghhGZSNIQQQmgmRUMIIYRmt0TROHv2LMHBwRw+fBgAu93OmDFjOHfuHL///jsvv/zyNfdd1c0Ui4uL6du3L5mZmSxatIjo6Giio6OZO3cuCxcuJCoqiujoaJYvX672M2fOHCZNmgTAY489RnR0NLGxscTGxrJs2TLi4uLo06cPw4cPV4fHxsbSvn17RowYoc5jzpw5LFmyhMjISGJiYnjvvffUeWRmZtK9e3cADh8+THBwMJs2barwet555x1efvllHnvsMXXYN998UyGubN68eYwePZrIyEiCg4Np164dkZGRREZG8sorr3Dq1KkK7SdNmsTatWvVnNq1a8e//vUv4uLiKiyTcrGxsXTq1IkNGzZUGP7KK6/w4IMPMmXKlIvGXchmszFnzhxat25NVFQU7du3Z+zYsWj9DkhmZiZt27a9aHhwcDDPPfcco0aNYvLkyReN37ZtG+3btyc2NpZvv/2WcePGVViO27Zt4/XXX1envXA5l/994bDMzEzuvfdeJk2aVOV78s033zBgwABiYmKYMmXKRe9jZeV9JCQk8NFHHxEcHMy0adMqtDl48CDBwcEsW7aM4OBgdu3aVWF89+7dyczMvNziq+DCdbDcypUrWblyJVFRUYwc6Xzi4ZdffsnChQsvO5/MzEzuuusuunXrRmxsLDExMXTv3p2ePXuSnZ0NQEpKCnFxcfTr14+YmBg++OCDi3IaOXKk2v5yTp48SWhoKB06dODOO+8kJCSEqKgo/vrXv7JmzZrLTvv222+zb9++K86jsm+++YbOnTtz+vRpddgHH3zA2LFjNU3brl07Hn/8cSZMmMA999yjfu4Adu3aRY8ePdixYwfTp0/n4Ycfpqzsyo9KrvNfub0eyn9BXv7/ypUr6dy5M25ubri5ueHr68v27dvp0qXLVfVb1c0UGzRowPvvv8+xY8dIS0tj586dJCYmotPpGDx4MBaLhc8++wybzUZUVBRdunQhOzubxMREunbtiqIoHDt2jG3btmE0Gjlx4gSPPPIIq1atwtfXl+HDhzN+/Hi6dOnCkSNHGDVqFAcOHGDz5s3Ur1+fvn37YrVaSUpKws3NjdGjR7N582Z69epVIfc1a9bQu3dvPvjgA77++mtmzpzJ5MmTNf3a3mq18tRTT/Hcc8/RsWNHVq5cyV133YVer8doNBIcHExGRgbh4eFs2bKF77//nvnz5zN48GDS09Or7NPf359u3bpRXFx80biff/6Z/fv34+JS8V48iYmJ7N+/n2nTpl1yZX/sscdwd3enrKwMPz8/kpOTmTBhAgcPHuQ///kPjz766CWnGzNmDPfeey/AJftfvLjio2UvnK6goICuXbvy5ptvsnbtWgoLCyu0TU9Px9PTk/j4+Cr7vhbnzp0jLCyMhg0bat6Yf/fdd7Rs2RIvLy927NiB3W7HYHDeOyk5ORkfH+c9vUwmE1OnTmX9+vV4eHhcrsur8vDDD1f4H+DBBx/kwQcfvOK0ZrOZsWPHEhcXBzg/k5GRkep6NGfOHNauXYu3tzdnz57lscce44477qjQ99KlSzXlmZWVhdVqpUGDBhiNRgoLC0lOTtY07d69e9V16Wrce++96k7Ae++9x/fff09CQgKrV6/WNH2bNm348MMPAdSd0nKbNm1i6tSpPPDAAzzwwAOMHTuWn376ibCwsMv2eUt85VZRFO666y6++OILGjVqRO/evVm9ejWe529UePjwYWbMmMHHH38MOCt0YmIis2fPvmy/iYmJ7N27l9dffx2Ad999ly+++ILJkyfz0ksvMWPGDDw8PNQ3YcaMGTRu3JgnnniCrKwsHnnkEZYuXcqUKVOIiori0KFDjBw5kscff5w77riD/Px8mjRpQuPGjXnllVcA54fCbDbj5eXFo48+yqBBg5g5cyZJSUn4+vrSs2dPOnbsyNy5c/nHP/5BamoqeXl5hIeHM2HCBEaOHMmmTZto3749PXr0ICUlhYCAAJ5//nn69+/PO++8w9dff83hw4dRFIV69erRtm1bTpw4QW5uLsXFxeoe+qJFi1iyZAn79+8HICYmhp07d1JcXIzdbsfhcPDiiy+ybNkyHA4HZ8+eVYtSYGAgJSUllJaWYrFY+Otf/8p3332HTqfDzc2NqKgo9YOhKAoeHh6MGDGCZcuWYbfbsdvt2Gw2jEYjNpsNvV6Pl5cXoaGhfP311+rtZ8oLRvn/bm5u5Ofn4+npSVlZGS4uLgwZMoQdO3Zw7NgxgoKCyMvL4/Tp09SvX5+ioiIcDgcA3t7eJCUlER8fT1FRET/88AO+vr6UlJTQoEEDioqKsFgs+Pn5Ac4jznPnzuHj40NJSQnnzp1Dp9MREBCAwWAgKytLzfOrr74iPj6ew4cP06hRI3799VfKyspo2rQphw8fxtvbm65du7J161aaNWtGQUEBR48exdPTE5vNhq+vL8XFxZw5cwaA2267jZKSEkpKStDpdCiKgl6vR6/XExgYSP369XnooYeYM2cOJSUlGI1GysrK8PHxoUmTJhQXF9O9e3eSkpI4e/YsZWVl6PV6SktLady4MRs3bmTGjBmsXr2aZs2aERYWxvTp01m+fDmffPIJeXl5mEwmbDYb4LwdUEBAAIsXL2bo0KHYbDZKSkrUz1L5+2gwGHA4HLi6umKz2QgICKCoqEgtuCaTCYPBgM1mw2az4XA4MBgMBAYGkpeXh9VqpaysjPr16zNkyBBWrFiBi4sLOp2OsrIyOnfuzI4dOygrK8PhcFSYr91uB5yFqLS0FKPRyF133cVPP/2krmPl60Jlt912G4GBgfz88884HA7sdjuurq7cfffdHDlyhMLCQho1asTChQt5/fXXSUtLw2Qy4erqil6vp0uXLmzatImgoCAyMzMJDg7mzjvv5NVXX2Xv3r0888wzvPjii3z88cc0adKEyMhIBg8eDEDPnj3Vz43FYuHEiRNs376dX3/9lUWLFrFixQrAWTTuuecetcC+9NJLDBkyhPbt2wMQHx9Pv379uO+++y673bslTk/pdDrq169PgwYNOHToEJ6enmrBAGjVqhW//PIL+fn5V9VvTk6OuoEA595ymzZt6NChAwC33367WjCOHTvGxo0b6d69O2+//TbR0dGEh4ezaNEixo0bR/36zrupFhYWEh4ezrvvvsuHH37I3r17yczM5NlnnyU2Npb//Oc/NGjQgNTUVCwWCzExMTRv3pwHH3yQdu3aUVpayqFDhxgyZAhffPEFp06dwmazkZqayqOPPkpWVhYdOnTAZrORnZ1Np06dsFqtzJ07lyFDhpCZmUlhYSE6nY4VK1ZQUlJCcXExGRkZGI1GHnnkEcLCwtDpdLz55pucPn0aT09Pnn32WX788Ufy8/OJiYlR907feustLBYLZ8+eBaB3794YDAZOnTpFUVERwcHBKIpCeno6JpOJli1bYrfbWbNmDYMHD6Zfv34AlJSU8P777+Pq6oqfnx/16jnvBnvhaSlvb2927dpFYGAgd9xxB2azmZKSEry8vMjPz0ev13P77bfj5eVFUFAQ3t7edOrUiWXLlqmFMD8/HxcXF/z9/SkoKMDPz49WrVqp43r06MEvv/zCuXPnADh9+jQWiwWLxULr1q3x9PTk3LlzmEwmSkpKcHd354477iA0NJROnTrRrFkzTp8+TYsWLRg1ahStW7cGnD9iBedR3JAhQ3Bzc6OsrIzCwkJatGhBaWmpevuczMxM6tevT6NGjbDZbDz22GMUFRUBzo2vr68vRUVF6PV6dDodJpNJHde2bVvOnDlDixYtWLJkCb6+vsTGxhIVFQU4T+XefvvtrFmzho8++ohGjRrRrl077Ha7eqSXnZ3N66+/zt69e3F1dVX7mTp1Kps2bcJms7FlyxYCAwMpKyujffv2HDhwAKvVyltvvUVhYSEWi0V937y8vNT13+FwoCgKTz75JLfddhtnzpzBZrPh6elJeHg4Xl5e2Gw2IiIimD59OuAsJHl5eWqB9vb2xmw28+GHH+Lv709RURFlZWXYbDbsdrv62Y+KiuLJJ59Ul7+Hhwd6vR5PT0/MZjM2m41p06apuZV/rsvpdDoaNWqEXq8nJCSEgwcPUlZWxqxZs5g1axZlZWXk5OSwZcsWHA4H8fHx/PDDDxw/fpzWrVuzb98+AgICOHv2LKmpqbRt25ZevXrh7e1NVlYW3333HQC7d+9m2LBhzJ49Wz2Fl5SUBDiPflxcXNi8eTPr1q2jZcuWjB8/vsJ2qSplZWX88ssv/OUvf1GHNWnShB9//PGy08EtUjQAfHx8qFevHseOHSMgIOCi8QEBAaxevZrY2FimTJnC1q1biY2NVffwq6L1ZopHjhzhiSee4KWXXuL222/n+eefZ/fu3fzwww9qkSjXrl075s6di6enJz4+Ptx+++3q0cx///tf9u/fT2JiIp9++ikjRowgKSmJjIwMdu3axffff49er8dkMnHixAmCgoJo06YNLi4ueHp6otPp8PHxoVOnTuqHJDw8nDNnzhAWFqYe0rdt25YOHToQGhqKj48PoaGh6p7ali1bOHLkCIqikJuby5133onJZKJTp068/fbbAHz77be0a9cOAL1ej9Vqxc3NebvlrVu34nA41L2xnJwcdDoder0eu91OREQEpaWlOBwOdu/erX44HA4HDRs2xGg00qpVK3UPtnyDGBoaylNPPUXLli3Jzs7m3LlzKIqizqv8/bn99tspLCzk+PHjWCwW8vPz1Q2Vw+EgLy8PHx8fFEXBx8eHdu3a4X7+duSxsbGEhYUxaNCgCs9zMZlM6vvu7e2NzWZj+fLluLi4qHvT5YXHzc0Nb29v9u3bx549e/jll1/Q6//4GFosFqZOnUqnTp1wcXGhsLAQb29vvLy81NOn3bt35/Dhw2qB+u9//8vZs2cpKSlBURQURcFqtRIYGKjGer1e7c9oNOLm5sZvv/3GbbfdViG/4OBg0tLSMJvNmEwm/va3vwGoywCgY8eObNiwgdzcXCwWC08//TRffvklBw4cIDg4mPbt2xMYGEhYWBgGg4GAgAD0ej0DBgzg//2//4e3tzd/+ctfcHNzo0mTJvj5+amnw3Q6HX5+fgQFBaltzGYzZrOZ++67j9LSUlq2bKkW0/L3taysDFdXV86cOUNBQQEFBQVYrVZeeeUVhg8fTseOHfHx8WH79u2cPn0aFxcXvv76a/U6Q0FBAXa7HV9fXwoLC9XCsn79egoKCjAYDOo98MxmszreYDCo8y9fJz/44APeffdd9Ho9RUVFeHh4YDQaOXv2LLt378bhcPDzzz/TrVs3MjIycDgcFBcXc/DgQf7973/TvHlzOnTogF6v5/Tp03z99dfqerN7927at29PTk4OmZmZrFu3jtjYWAAWLlyIyWTiqaeeumgbVNnYsWO57777KhSXESNGsHr1alJSUi477S1TNJo0aYJOp0On02E0VnFve4OB8PBwkpKS+Oc//6kems+aNatCu4ULF6oXoc+cOXPFmymmpaWpF6LuvvtuDh48CDg3Hoqi8NNPPxEbG8vbb7/N1q1beeGFF9i9e7c6fb169QgKCsLHxwdXV1d69OjB999/z969e+nevTt5eXl07dqVlJQU3njjDRwOh7rXeezYMXJycgDnHmReXh6FhYVs27aNM2fOsH//fpYtW6YedZRv+AwGg7qMdDqduuE1mUxMnDiRF154AYPBQIsWLWjUqBFnz55FURR+/fVXFEXB3d1dnb68sDZp0gSAwYMH43A4aNDA+SyLDz74ADc3N/VQ++TJk+pGtH79+pjNzmcGmM1mQkJCGDFiBFarVd3TLz9CcHd3Jz8/nyNHjuDq6kqTJk3U13HhEWRwcDCBgYF07twZi8WibjSDgoIICAjg/vvvp1evXuq60rBhQ7UA7t+/nwMHDrB161Z1WPnyKf/w6XQ6XF1d1UJYnl95cdPpdJw6dYqAgACsVisOh6NC0TCbzbzzzjt8+eWXVa6jgLps7XY7RqORuLg4mjZtSkhICI0aNUKn02EwGPD19VVP85QXksjISPV9uTC/cq6uroSEhJCWlkZpaSkdO3YEqJCjv78/zZs3p169eri5ubFkyRJWrVrFfffdV+Vnq1z5PA0GAwaDQT1dVnlnq/K1q/L34sJpLtSrVy8MBgNubm7Y7XbMZjNvvvkm4LyW4OHhwd13303btm0ZPnw4rq6ueHt7ExYWxm+//QZAo0aN1CNTq9WqLpeff/4Zg8FAgwYN1PXIYDCoO1iBgYGYTKYKy3H9+vXMnDmToKAg7rnnngq5lp8C8/Hx4fXXX1c39G3atOHFF1/EYrGQmZnJ4cOH6dixIykpKZw9e5YVK1bw6aef4uLiwr/+9S/69+/P559/zsaNG4mNjSUlJUX9YoUWb731Frt27apwDXH9+vVERkbSu3fvy057yxSNJUuWANC0aVOysrIuGp+dnU3jxo2v2M8LL7xAUlISSUlJPPXUU5e9mWJOTg6jR49m3rx5REdHk5mZyZQpUygrK6OsrIxGjRoxffp0kpKSeP755+nevTv9+/dn7ty5lJaWUlxcTGZmJvn5+RQWFmK329mxYwe+vr7cfvvtuLu7Y7FYSE5OVvfk3NzcKCgoIDIykk6dOpGXl4e7uztmsxlXV1fc3d3p3LkzvXr1onXr1syfP5+GDRvy888/V7i4mZaWxm+//YaiKKSlpQHOQ9rWrVvzxRdfYLfbOXPmDAcPHsRoNLJixQrGjx8PQJcuXSp8U0Sv16vfXNu2bRs6nY68vDzAuYdnsVjYvn07drud7du3q0deR44cwdvb+SCl0tJSvvzyS7766ivGjRunnv4q/yAfOnSI4uJirFYr4eHhvP322+r56ubNmwOoh/EOh4PMzExKS0vVDVjXrl0pLCwkNTWVlStX4uLiQlFRERs2bOCzzz4DnDseRqORiIgIhg0bBqAeoRw9elTdcFR1tFl+JFVYWIjNZiM+Pl4tcBfy9vame/fuNG3aVN3zLX+N5YVk+/bttGrVipKSEnUDlp2dza+//srJkydRFAUXFxf279+vbkTL89y8eTMWiwVfX1/8/Pw4ffo0BoOBI0eOqDn06dOHN998U71+UDm/wsJCHnzwQXJyctQjun/84x8UFBTw008/ceDAAU6cOMEPP/yA3W4nLy8Pm83GunXr1PPlJ06coKSkhKysLHJyctSNqaIo2O12FEWp8nNar149MjMz1WtkABkZGURERFBYWIjZbMZisTBhwgTA+aWXgoICiouL+fbbb/niiy/U9Sk0NFTt49ixY2pBKz+q1ul0HD16FKPRyLlz5ypcgynfCXB3d1eLcrmjR48CkJeXp37xo3znIjQ0lNOnT6MoCm3atOHvf/+7enpzyZIlNGjQgLKyMnJzc7nvvvt47733yM/PZ+LEiTRp0oTZs2fz8ccfExwczKeffkpgYCBnzpxhzpw5LFq0SD2ivxI3NzdatGjBr7/+qg5LT0+/qMhV5ZYpGrGxsWRnZxMSEkJeXp66Nw7OC+F33HGHuvd77733XnQRvHz6C114M8X+/fvTt2/fCjdTTEhIoLS0lNmzZxMbG8v8+fPx9fWlf//+DBw4kHbt2hEdHV2hz27dutGlSxe1zdChQxk9ejSPPPIIUVFRNGrUiJYtW6qn2PLz8+nYsSP//ve/mTBhAnl5eYSFhZGcnMy2bdtwdXXl9OnThIaGYjKZKC4u5pFHHuH48eP8/PPPTJ8+nYKCAgD18BqgRYsWxMfHk5OTQ/369WnWrBlWq5Xo6GjS0tIwGAx07tyZ9u3bYzab+eKLL9Q9wKVLl6pHYAaDgYYNG6qnVjIzM1EURT2H//jjj6MoCo0aNVI3gG3atKF58+aUlpaqy7z8gnx6ejqDBw9Wv4JYvnEoKioiPz8fDw8PNm/eTHh4OMXFxeh0Olq2bAk4L0z/+uuv6p7cnXfeyalTp3B1deWjjz6ipKQEh8NBz549+f333zEajWpRA9i3bx+KovDf//6Xzp07A84jA6PRqF6cv5RmzZrxv//9j+LiYtzd3Zk6daq6sah8URicp6CsViv9+vVTN6wnT55U+8rLy+O3337DbDar32YyGo1qQa5Xrx5GoxGr1YrVagWc10tyc3Np2rQpBoOBtm3bkpeXR2pqKhs3bqywDh48eLDKDdCECRPYs2cPCQkJtG7dGkVReOKJJ3A4HMyaNYsePXqg0+no06cPWVlZ6HQ6du3aRVhYGN7e3uoTN8t3UGw2G4WFheqF7vr163Pq1Cnefffdi47CyteDwMBA0tPTmTdvHgA//fQT+/fvR6fTUVpaqn6Bo/yz8p///IePP/6Yc+fO0axZMxRFobi4mOXLl6vXKxRFoaCggMLCQurVq6e2y8nJwWKxqKfIAHWnT1EUduzYgV6vr/DNuBdffJH4+HjKyspo06aNup4sWLCAsLAwgoODycnJoVOnTiiKgtFopEePHuTl5amnbOfNm8c999zDqVOnCAkJUU9BBQUF8corrzBnzhz8/f0ZMGAAb7zxBjabjRdeeEE9C6Ll670uLi4Vri1ZrdbLHimqlFvQv//9b2XFihVqPHPmTGXbtm2XnWbmzJlKUVFRNWd29Q4dOqT07dtX6du3rzJgwABlzJgxyuuvv66MHDlS6du3rxIbG6skJCSobR966CGlX79+yv33368sX75c2bNnjzJ06FBFURRl6NChyp49ezTN98K2mzdvVoKDg5V+/fqp/+Lj45VWrVopiqIoCQkJSt++fZVWrVop48ePV5dj+fhyiYmJyv33368oiqIUFBQod955p/Ldd99V+TqHDh2qPPPMM8qJEyeUrl27KgMGDFAOHjyolJWVKZMnT1Z69eqljBgxQhk8eLCa53fffaesXbtWURRFKSsrUwYMGKB89913FZbVvHnzlLVr1ypDhw5Vdu7cqURFRSk9e/ZUHnjgAeWee+5RxowZo8yfP18pKiqqchlfuFxOnDihdOvW7aJl53A4lEOHDimxsbHKli1blKefflrTMv8zKi9rRXF+Do4cOaIoiqKkp6crAwYMuK7zXL58uXL33XcrL7/8coXhe/bsUdeT8nVPURTlzJkzysKFCxW73a4oiqK89tprykcffXTZebz88svKmjVrqhy3bds2ZevWrYqiKEphYaHSvXt3JS8vT1PuF34u6hqHw6H8/vvvSs+ePZXS0tJLtqv8Giovq9dee03ZsmWLGo8aNUo5ePDgFed/SxaNsrIy5dlnn1VKSkqU3377TRk3btxl2zscDiUpKamGsqsZl/uw3Qjy8vKUJ554QomJiVH69u2rfPDBB9dlmku1WbNmzUUbv2u1fPly5f7771cWLVqkdOrUSdmwYcN16fdyqioaX331lRITE6PExsYqgwcPVtLT06/rPK+2aDgcDuW1115T+vTpo/Tt21d5+eWXFYvFctl5XG49Pn78uLqT1K9fP2XdunWac6/LRWPjxo3Kvffeq2zcuPGy7fbs2aOEhYUpw4cPV8aPH6907NixwrJKT09XevXqpXz99dfK1KlTlccff1yx2WxXnP8t8TsNod3x48cv+WvTf/7zn1X+MrquuxlfkxC1RYqGEEIIzW6ZC+FCCCH+PCkaQgghNJOiIcR18s0339C3b9/LtgkODlbvD6XVpEmTWLZs2Z9JTYjrRoqGEEIIzW6JW6MLUZOOHj3KjBkzOHv2LLm5uYSEhPDWW2+pPw576623OHDggHoX4G7dugGwatUqVq5cicPhwMvLi6lTp6q/ZheirpCiIcR1lpCQQP/+/YmNjcVqtRIXF8dXX32l3vepcePGzJgxg8OHD/PYY4+xceNGfvnlF9atW8cnn3yCm5sbO3fuZMyYMRV+qS1EXSBFQ4jrbOLEiezatYulS5eqN4288DYh5Q8batWqFc2bN+f7778nLS2NjIwMHnroIbVdYWHhVd+uX4jqJkVDiOts/Pjx2O12+vTpQ9euXdWbCJa78H5K5Q8CcjgcxMbGMnHiRHV4Tk6Oej80IeoKuRAuxHW2c+dORo8erT7YqPxur+USExMB+PHHHzl+/DihoaF07tyZzz//XL2V/cqVKxk+fHjNJy/EFciRhhDX2bhx4xg9ejTu7u54eHjQsWNHjh8/ro4/ceIE/fv3R6fTMX/+fLy8vOjcuTMjR47kiSeeQKfT4eHhwaJFizQ9s12ImiS3ERFCCKGZnJ4SQgihmRQNIYQQmknREEIIoZkUDSGEEJpJ0RBCCKGZFA0hhBCaSdEQQgihmRQNIYQQmv1/kMc41oeFDDAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"label\", data=df)\n",
    "plt.title('Label Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df\n",
    "\n",
    "data=df1.iloc[:,:-1]\n",
    "label=df1.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoded = LabelEncoder().fit_transform(label)\n",
    "\n",
    "#60% train, 20% test, 20% validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label_encoded, test_size=0.2, random_state=22, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset contains:  (40584, 256)  data\n",
      "Testing dataset contains:  (13528, 256)  data\n",
      "Validation dataset contains:  (13528, 256)  data\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset contains: ', X_train.shape, ' data')\n",
    "print('Testing dataset contains: ', X_test.shape, ' data')\n",
    "print('Validation dataset contains: ', X_val.shape, ' data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_col = [\"Model\",\"training duration(ms)\", \"predicting duration(ms)\", \"accuracy score\"]\n",
    "performance_result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12004824400157932\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('Y Test (True Values)')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs. Actual Values ')\n",
    "\n",
    "r2 = lr_model.score(X_test,y_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.92      0.44       208\n",
      "           1       0.30      0.78      0.43       213\n",
      "           2       0.36      0.77      0.49       211\n",
      "           3       0.17      0.24      0.20       201\n",
      "           4       0.13      0.48      0.21       214\n",
      "           5       0.33      0.65      0.44       194\n",
      "           6       0.55      0.17      0.26       209\n",
      "           7       0.25      0.46      0.33       197\n",
      "           8       0.31      0.10      0.15       184\n",
      "           9       0.42      0.17      0.25       190\n",
      "          10       0.33      0.09      0.14       194\n",
      "          11       0.58      0.21      0.31       214\n",
      "          12       0.75      0.25      0.37       210\n",
      "          13       0.49      0.26      0.34       186\n",
      "          14       1.00      0.11      0.20       188\n",
      "          15       0.52      0.26      0.35       190\n",
      "          16       0.18      0.77      0.29       191\n",
      "          17       0.83      0.03      0.05       180\n",
      "          18       0.30      0.32      0.31       211\n",
      "          19       0.90      0.28      0.43        32\n",
      "          20       0.67      0.27      0.38       197\n",
      "          21       0.49      0.41      0.45       214\n",
      "          22       0.87      0.37      0.52       213\n",
      "          23       0.86      0.29      0.43       204\n",
      "          24       0.62      0.37      0.47       201\n",
      "          25       0.56      0.40      0.46       199\n",
      "          26       0.37      0.26      0.30       218\n",
      "          27       0.57      0.07      0.12       189\n",
      "          28       0.34      0.72      0.46       165\n",
      "          29       0.35      0.77      0.49       172\n",
      "          30       0.97      0.46      0.63       211\n",
      "          31       0.36      0.80      0.49       196\n",
      "          32       0.51      0.18      0.27       212\n",
      "          33       0.90      0.77      0.83       190\n",
      "          34       0.93      0.56      0.70       193\n",
      "          35       0.79      0.15      0.26       196\n",
      "          36       0.50      0.70      0.58       168\n",
      "          37       0.87      0.40      0.54       207\n",
      "          38       1.00      0.50      0.67         4\n",
      "          39       0.34      0.27      0.30       196\n",
      "          40       1.00      0.90      0.95        10\n",
      "          41       0.17      0.24      0.20        46\n",
      "          42       0.76      0.54      0.63        84\n",
      "          43       0.95      0.60      0.74       139\n",
      "          44       0.82      0.58      0.68        53\n",
      "          45       0.33      0.65      0.44       210\n",
      "          46       0.50      0.45      0.48        11\n",
      "          47       0.87      0.43      0.58       209\n",
      "          48       0.50      0.72      0.59       201\n",
      "          49       0.28      0.51      0.36       202\n",
      "          50       0.74      0.33      0.46       206\n",
      "          51       0.25      0.53      0.34       206\n",
      "          52       0.88      0.75      0.81        20\n",
      "          53       0.33      0.95      0.48       118\n",
      "          54       0.81      0.46      0.59       185\n",
      "          55       0.92      0.61      0.74       196\n",
      "          56       0.98      0.71      0.83       181\n",
      "          57       0.74      0.57      0.65        96\n",
      "          58       0.82      0.41      0.55        34\n",
      "          59       0.86      0.54      0.66       121\n",
      "          60       0.62      0.60      0.61        93\n",
      "          61       0.57      0.27      0.37       184\n",
      "          62       1.00      0.43      0.60        74\n",
      "          63       0.73      0.32      0.44       230\n",
      "          64       0.68      0.75      0.72       141\n",
      "          65       0.21      0.43      0.28        58\n",
      "          66       0.67      0.22      0.33       202\n",
      "          67       0.77      0.59      0.66       206\n",
      "          68       0.85      0.59      0.70        37\n",
      "          69       0.96      0.66      0.78       194\n",
      "          70       0.32      0.87      0.47       202\n",
      "          71       0.78      0.20      0.32       210\n",
      "          72       0.89      0.75      0.82       188\n",
      "          73       0.95      0.36      0.52       196\n",
      "          74       0.81      0.55      0.65       205\n",
      "          75       0.50      0.23      0.32       180\n",
      "          76       0.73      0.30      0.42       197\n",
      "          77       0.82      0.31      0.45       119\n",
      "          78       0.47      0.19      0.28       190\n",
      "          79       0.84      0.55      0.66       187\n",
      "          80       0.77      0.74      0.75        77\n",
      "          81       0.71      0.71      0.71        68\n",
      "\n",
      "    accuracy                           0.45     13528\n",
      "   macro avg       0.62      0.47      0.47     13528\n",
      "weighted avg       0.60      0.45      0.45     13528\n",
      "\n"
     ]
    }
   ],
   "source": [
    " from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "train_start = time.time()\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "KNN_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = KNN_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['KNN',traing_time,predict_time,accuracy])\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.70      0.46       208\n",
      "           1       0.47      0.72      0.57       213\n",
      "           2       0.46      0.79      0.58       211\n",
      "           3       0.33      0.32      0.33       201\n",
      "           4       0.27      0.53      0.35       214\n",
      "           5       0.40      0.96      0.56       194\n",
      "           6       0.51      0.60      0.56       209\n",
      "           7       0.39      0.56      0.46       197\n",
      "           8       0.30      0.34      0.32       184\n",
      "           9       0.48      0.49      0.49       190\n",
      "          10       0.33      0.35      0.34       194\n",
      "          11       0.43      0.43      0.43       214\n",
      "          12       0.57      0.54      0.56       210\n",
      "          13       0.52      0.54      0.53       186\n",
      "          14       0.61      0.46      0.53       188\n",
      "          15       0.36      0.49      0.42       190\n",
      "          16       0.39      0.66      0.49       191\n",
      "          17       0.44      0.58      0.50       180\n",
      "          18       0.58      0.65      0.61       211\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       0.46      0.23      0.31       197\n",
      "          21       0.43      0.44      0.43       214\n",
      "          22       0.72      0.69      0.71       213\n",
      "          23       0.54      0.39      0.45       204\n",
      "          24       0.42      0.43      0.43       201\n",
      "          25       0.48      0.59      0.53       199\n",
      "          26       0.48      0.32      0.38       218\n",
      "          27       0.34      0.38      0.36       189\n",
      "          28       0.65      0.64      0.64       165\n",
      "          29       0.83      0.57      0.68       172\n",
      "          30       0.57      0.48      0.52       211\n",
      "          31       0.34      0.52      0.41       196\n",
      "          32       0.56      0.41      0.47       212\n",
      "          33       0.57      0.66      0.61       190\n",
      "          34       0.77      0.85      0.81       193\n",
      "          35       0.65      0.60      0.62       196\n",
      "          36       0.80      0.33      0.46       168\n",
      "          37       0.79      0.55      0.65       207\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.24      0.27      0.25       196\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00        46\n",
      "          42       0.00      0.00      0.00        84\n",
      "          43       0.73      0.47      0.57       139\n",
      "          44       0.00      0.00      0.00        53\n",
      "          45       0.51      0.53      0.52       210\n",
      "          46       0.00      0.00      0.00        11\n",
      "          47       0.73      0.67      0.70       209\n",
      "          48       0.48      0.60      0.53       201\n",
      "          49       0.48      0.53      0.51       202\n",
      "          50       0.39      0.44      0.41       206\n",
      "          51       0.36      0.22      0.27       206\n",
      "          52       0.00      0.00      0.00        20\n",
      "          53       1.00      0.12      0.21       118\n",
      "          54       0.62      0.49      0.55       185\n",
      "          55       0.68      0.77      0.72       196\n",
      "          56       0.86      0.86      0.86       181\n",
      "          57       1.00      0.28      0.44        96\n",
      "          58       0.00      0.00      0.00        34\n",
      "          59       0.72      0.39      0.51       121\n",
      "          60       0.00      0.00      0.00        93\n",
      "          61       0.46      0.57      0.50       184\n",
      "          62       1.00      0.14      0.24        74\n",
      "          63       0.58      0.42      0.49       230\n",
      "          64       0.82      0.66      0.73       141\n",
      "          65       0.00      0.00      0.00        58\n",
      "          66       0.47      0.45      0.46       202\n",
      "          67       0.73      0.83      0.78       206\n",
      "          68       0.00      0.00      0.00        37\n",
      "          69       0.81      0.78      0.80       194\n",
      "          70       0.65      0.89      0.75       202\n",
      "          71       0.77      0.50      0.61       210\n",
      "          72       0.78      0.81      0.80       188\n",
      "          73       0.68      0.61      0.64       196\n",
      "          74       0.46      0.71      0.56       205\n",
      "          75       0.45      0.45      0.45       180\n",
      "          76       0.65      0.68      0.66       197\n",
      "          77       0.82      0.54      0.65       119\n",
      "          78       0.39      0.31      0.34       190\n",
      "          79       0.67      0.47      0.55       187\n",
      "          80       1.00      0.03      0.05        77\n",
      "          81       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.52     13528\n",
      "   macro avg       0.48      0.44      0.43     13528\n",
      "weighted avg       0.53      0.52      0.50     13528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunao\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "train_start = time.time()\n",
    "svm_classifier = svm.SVC(kernel='rbf',gamma=0.001,C=5)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['SVM',traing_time,predict_time,accuracy])\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.07      0.12       208\n",
      "           1       0.29      0.22      0.25       213\n",
      "           2       0.49      0.16      0.24       211\n",
      "           3       0.34      0.05      0.09       201\n",
      "           4       0.39      0.07      0.13       214\n",
      "           5       0.59      0.20      0.29       194\n",
      "           6       0.38      0.11      0.18       209\n",
      "           7       0.33      0.03      0.06       197\n",
      "           8       0.40      0.01      0.02       184\n",
      "           9       0.64      0.16      0.25       190\n",
      "          10       0.19      0.05      0.07       194\n",
      "          11       0.55      0.10      0.17       214\n",
      "          12       0.16      0.33      0.21       210\n",
      "          13       0.68      0.14      0.23       186\n",
      "          14       0.12      0.11      0.11       188\n",
      "          15       0.34      0.27      0.30       190\n",
      "          16       1.00      0.01      0.01       191\n",
      "          17       0.46      0.18      0.26       180\n",
      "          18       0.57      0.30      0.40       211\n",
      "          19       0.19      0.94      0.32        32\n",
      "          20       0.10      0.01      0.01       197\n",
      "          21       0.25      0.03      0.06       214\n",
      "          22       0.40      0.15      0.22       213\n",
      "          23       0.54      0.20      0.29       204\n",
      "          24       0.33      0.03      0.05       201\n",
      "          25       0.71      0.12      0.21       199\n",
      "          26       0.40      0.02      0.04       218\n",
      "          27       0.29      0.02      0.04       189\n",
      "          28       0.37      0.34      0.35       165\n",
      "          29       0.43      0.48      0.45       172\n",
      "          30       0.53      0.20      0.29       211\n",
      "          31       0.24      0.78      0.36       196\n",
      "          32       0.19      0.25      0.21       212\n",
      "          33       0.15      0.13      0.14       190\n",
      "          34       0.19      0.94      0.32       193\n",
      "          35       0.27      0.44      0.34       196\n",
      "          36       0.42      0.73      0.53       168\n",
      "          37       0.80      0.38      0.52       207\n",
      "          38       1.00      0.50      0.67         4\n",
      "          39       0.06      0.23      0.09       196\n",
      "          40       0.77      1.00      0.87        10\n",
      "          41       0.27      0.74      0.39        46\n",
      "          42       0.28      0.39      0.33        84\n",
      "          43       0.60      0.50      0.55       139\n",
      "          44       0.76      0.91      0.83        53\n",
      "          45       0.49      0.12      0.19       210\n",
      "          46       0.53      0.73      0.62        11\n",
      "          47       0.20      0.18      0.19       209\n",
      "          48       0.32      0.21      0.25       201\n",
      "          49       0.09      0.24      0.13       202\n",
      "          50       0.19      0.26      0.22       206\n",
      "          51       0.08      0.04      0.05       206\n",
      "          52       0.39      0.95      0.55        20\n",
      "          53       0.35      1.00      0.52       118\n",
      "          54       0.35      0.45      0.40       185\n",
      "          55       0.37      0.52      0.43       196\n",
      "          56       0.60      0.88      0.72       181\n",
      "          57       0.64      0.91      0.75        96\n",
      "          58       0.24      0.29      0.27        34\n",
      "          59       0.54      0.44      0.48       121\n",
      "          60       0.28      0.65      0.39        93\n",
      "          61       0.24      0.17      0.20       184\n",
      "          62       0.11      0.89      0.20        74\n",
      "          63       0.57      0.11      0.19       230\n",
      "          64       0.58      0.81      0.68       141\n",
      "          65       0.11      0.09      0.10        58\n",
      "          66       0.23      0.16      0.19       202\n",
      "          67       0.74      0.54      0.62       206\n",
      "          68       0.12      0.65      0.21        37\n",
      "          69       0.35      0.22      0.27       194\n",
      "          70       0.52      0.67      0.58       202\n",
      "          71       0.70      0.28      0.40       210\n",
      "          72       0.41      0.86      0.55       188\n",
      "          73       0.50      0.44      0.47       196\n",
      "          74       0.55      0.41      0.47       205\n",
      "          75       0.36      0.14      0.21       180\n",
      "          76       0.48      0.13      0.21       197\n",
      "          77       0.49      0.55      0.51       119\n",
      "          78       0.09      0.06      0.07       190\n",
      "          79       0.58      0.16      0.25       187\n",
      "          80       0.11      0.29      0.16        77\n",
      "          81       0.07      0.88      0.14        68\n",
      "\n",
      "    accuracy                           0.29     13528\n",
      "   macro avg       0.39      0.36      0.30     13528\n",
      "weighted avg       0.39      0.29      0.27     13528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "train_start = time.time()\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['NB',traing_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85       208\n",
      "           1       0.69      0.62      0.66       213\n",
      "           2       0.78      0.65      0.71       211\n",
      "           3       0.48      0.31      0.38       201\n",
      "           4       0.65      0.66      0.65       214\n",
      "           5       0.69      0.85      0.76       194\n",
      "           6       0.65      0.44      0.53       209\n",
      "           7       0.48      0.43      0.46       197\n",
      "           8       0.39      0.25      0.30       184\n",
      "           9       0.57      0.51      0.54       190\n",
      "          10       0.59      0.47      0.53       194\n",
      "          11       0.56      0.42      0.48       214\n",
      "          12       0.68      0.57      0.62       210\n",
      "          13       0.59      0.52      0.55       186\n",
      "          14       0.64      0.52      0.57       188\n",
      "          15       0.56      0.55      0.56       190\n",
      "          16       0.70      0.59      0.64       191\n",
      "          17       0.56      0.47      0.51       180\n",
      "          18       0.75      0.68      0.71       211\n",
      "          19       0.78      0.91      0.84        32\n",
      "          20       0.74      0.86      0.80       197\n",
      "          21       0.82      0.87      0.84       214\n",
      "          22       0.78      0.84      0.81       213\n",
      "          23       0.62      0.59      0.60       204\n",
      "          24       0.79      0.83      0.81       201\n",
      "          25       0.77      0.93      0.85       199\n",
      "          26       0.77      0.77      0.77       218\n",
      "          27       0.53      0.45      0.49       189\n",
      "          28       0.83      0.88      0.86       165\n",
      "          29       0.84      0.97      0.90       172\n",
      "          30       0.83      0.82      0.83       211\n",
      "          31       0.72      0.69      0.70       196\n",
      "          32       0.61      0.42      0.50       212\n",
      "          33       0.84      0.88      0.86       190\n",
      "          34       0.84      0.84      0.84       193\n",
      "          35       0.68      0.54      0.60       196\n",
      "          36       0.83      0.98      0.90       168\n",
      "          37       0.82      0.92      0.86       207\n",
      "          38       1.00      0.50      0.67         4\n",
      "          39       0.67      0.74      0.70       196\n",
      "          40       1.00      1.00      1.00        10\n",
      "          41       0.57      0.35      0.43        46\n",
      "          42       0.84      0.86      0.85        84\n",
      "          43       0.91      0.98      0.94       139\n",
      "          44       0.90      0.98      0.94        53\n",
      "          45       0.75      0.87      0.81       210\n",
      "          46       0.89      0.73      0.80        11\n",
      "          47       0.88      0.84      0.86       209\n",
      "          48       0.86      0.91      0.89       201\n",
      "          49       0.75      0.82      0.78       202\n",
      "          50       0.78      0.86      0.82       206\n",
      "          51       0.79      0.95      0.86       206\n",
      "          52       0.83      0.95      0.88        20\n",
      "          53       0.90      0.98      0.94       118\n",
      "          54       0.87      0.93      0.90       185\n",
      "          55       0.92      0.87      0.89       196\n",
      "          56       0.89      0.97      0.93       181\n",
      "          57       0.82      0.97      0.89        96\n",
      "          58       0.79      0.91      0.85        34\n",
      "          59       0.95      1.00      0.98       121\n",
      "          60       0.76      1.00      0.87        93\n",
      "          61       0.78      0.77      0.77       184\n",
      "          62       0.93      1.00      0.96        74\n",
      "          63       0.82      0.86      0.84       230\n",
      "          64       0.85      1.00      0.92       141\n",
      "          65       0.65      0.90      0.75        58\n",
      "          66       0.77      0.88      0.82       202\n",
      "          67       0.91      0.92      0.92       206\n",
      "          68       0.82      0.97      0.89        37\n",
      "          69       0.87      0.97      0.92       194\n",
      "          70       0.90      0.93      0.91       202\n",
      "          71       0.77      0.74      0.75       210\n",
      "          72       0.93      0.96      0.95       188\n",
      "          73       0.82      0.85      0.84       196\n",
      "          74       0.86      0.93      0.89       205\n",
      "          75       0.79      0.88      0.83       180\n",
      "          76       0.80      0.81      0.80       197\n",
      "          77       0.82      0.84      0.83       119\n",
      "          78       0.71      0.64      0.67       190\n",
      "          79       0.84      0.94      0.88       187\n",
      "          80       0.86      0.97      0.91        77\n",
      "          81       0.84      0.97      0.90        68\n",
      "\n",
      "    accuracy                           0.76     13528\n",
      "   macro avg       0.77      0.78      0.77     13528\n",
      "weighted avg       0.75      0.76      0.75     13528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "train_start = time.time()\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['DT',traing_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.04       208\n",
      "           1       0.34      0.16      0.22       213\n",
      "           2       0.20      0.67      0.31       211\n",
      "           3       0.00      0.00      0.00       201\n",
      "           4       0.19      0.07      0.10       214\n",
      "           5       0.36      0.45      0.40       194\n",
      "           6       0.42      0.10      0.16       209\n",
      "           7       0.11      0.45      0.18       197\n",
      "           8       1.00      0.01      0.01       184\n",
      "           9       0.20      0.61      0.30       190\n",
      "          10       0.00      0.00      0.00       194\n",
      "          11       0.64      0.03      0.06       214\n",
      "          12       0.22      0.08      0.12       210\n",
      "          13       0.25      0.01      0.01       186\n",
      "          14       0.11      0.51      0.18       188\n",
      "          15       0.23      0.13      0.16       190\n",
      "          16       0.65      0.07      0.12       191\n",
      "          17       0.34      0.26      0.29       180\n",
      "          18       0.47      0.22      0.30       211\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       0.00      0.00      0.00       197\n",
      "          21       0.00      0.00      0.00       214\n",
      "          22       0.21      0.01      0.03       213\n",
      "          23       0.00      0.00      0.00       204\n",
      "          24       0.32      0.04      0.07       201\n",
      "          25       0.45      0.07      0.11       199\n",
      "          26       0.00      0.00      0.00       218\n",
      "          27       0.07      0.01      0.01       189\n",
      "          28       0.00      0.00      0.00       165\n",
      "          29       0.00      0.00      0.00       172\n",
      "          30       0.68      0.06      0.11       211\n",
      "          31       0.33      0.51      0.40       196\n",
      "          32       0.22      0.39      0.28       212\n",
      "          33       0.18      0.44      0.25       190\n",
      "          34       0.21      0.97      0.35       193\n",
      "          35       0.31      0.22      0.26       196\n",
      "          36       0.40      0.01      0.02       168\n",
      "          37       0.31      0.40      0.35       207\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       0.00      0.00      0.00       196\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00        46\n",
      "          42       0.00      0.00      0.00        84\n",
      "          43       0.00      0.00      0.00       139\n",
      "          44       0.00      0.00      0.00        53\n",
      "          45       0.00      0.00      0.00       210\n",
      "          46       0.00      0.00      0.00        11\n",
      "          47       0.28      0.59      0.38       209\n",
      "          48       0.13      0.76      0.22       201\n",
      "          49       0.15      0.29      0.20       202\n",
      "          50       0.00      0.00      0.00       206\n",
      "          51       0.00      0.00      0.00       206\n",
      "          52       0.00      0.00      0.00        20\n",
      "          53       0.00      0.00      0.00       118\n",
      "          54       0.33      0.01      0.02       185\n",
      "          55       0.17      0.26      0.20       196\n",
      "          56       0.48      0.34      0.39       181\n",
      "          57       0.00      0.00      0.00        96\n",
      "          58       0.00      0.00      0.00        34\n",
      "          59       0.00      0.00      0.00       121\n",
      "          60       0.00      0.00      0.00        93\n",
      "          61       0.17      0.41      0.24       184\n",
      "          62       0.00      0.00      0.00        74\n",
      "          63       0.00      0.00      0.00       230\n",
      "          64       0.00      0.00      0.00       141\n",
      "          65       0.00      0.00      0.00        58\n",
      "          66       0.50      0.07      0.13       202\n",
      "          67       0.22      0.63      0.33       206\n",
      "          68       0.00      0.00      0.00        37\n",
      "          69       0.38      0.46      0.42       194\n",
      "          70       0.14      0.90      0.25       202\n",
      "          71       0.56      0.09      0.16       210\n",
      "          72       0.22      0.59      0.32       188\n",
      "          73       0.18      0.29      0.22       196\n",
      "          74       0.13      0.68      0.21       205\n",
      "          75       0.21      0.03      0.06       180\n",
      "          76       0.56      0.11      0.19       197\n",
      "          77       0.00      0.00      0.00       119\n",
      "          78       0.19      0.06      0.09       190\n",
      "          79       0.20      0.01      0.01       187\n",
      "          80       0.00      0.00      0.00        77\n",
      "          81       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.20     13528\n",
      "   macro avg       0.18      0.17      0.11     13528\n",
      "weighted avg       0.22      0.20      0.14     13528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunao\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "train_start = time.time()\n",
    "RF_classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RF_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = RF_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['RF',traing_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.87      0.18      0.30       213\n",
      "           2       0.84      0.25      0.38       211\n",
      "           3       1.00      0.00      0.01       201\n",
      "           4       0.00      0.00      0.00       214\n",
      "           5       0.37      0.58      0.45       194\n",
      "           6       0.50      0.50      0.50       209\n",
      "           7       0.00      0.00      0.00       197\n",
      "           8       1.00      0.01      0.01       184\n",
      "           9       0.08      0.92      0.14       190\n",
      "          10       0.48      0.07      0.12       194\n",
      "          11       0.00      0.00      0.00       214\n",
      "          12       0.91      0.05      0.09       210\n",
      "          13       0.84      0.09      0.16       186\n",
      "          14       0.30      0.49      0.37       188\n",
      "          15       1.00      0.02      0.04       190\n",
      "          16       0.43      0.29      0.34       191\n",
      "          17       0.74      0.14      0.23       180\n",
      "          18       0.50      0.00      0.01       211\n",
      "          19       0.07      0.69      0.12        32\n",
      "          20       0.00      0.00      0.00       197\n",
      "          21       0.79      0.05      0.10       214\n",
      "          22       1.00      0.10      0.19       213\n",
      "          23       0.86      0.09      0.17       204\n",
      "          24       0.67      0.13      0.22       201\n",
      "          25       0.00      0.00      0.00       199\n",
      "          26       0.57      0.02      0.04       218\n",
      "          27       0.00      0.00      0.00       189\n",
      "          28       1.00      0.05      0.09       165\n",
      "          29       1.00      0.01      0.02       172\n",
      "          30       0.55      0.45      0.50       211\n",
      "          31       0.23      0.70      0.35       196\n",
      "          32       0.33      0.55      0.41       212\n",
      "          33       0.74      0.38      0.51       190\n",
      "          34       0.56      0.87      0.68       193\n",
      "          35       0.76      0.40      0.52       196\n",
      "          36       0.66      0.48      0.56       168\n",
      "          37       0.42      0.65      0.51       207\n",
      "          38       0.00      0.00      0.00         4\n",
      "          39       1.00      0.01      0.02       196\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00        46\n",
      "          42       0.00      0.00      0.00        84\n",
      "          43       0.88      0.16      0.27       139\n",
      "          44       0.92      0.21      0.34        53\n",
      "          45       0.45      0.39      0.42       210\n",
      "          46       0.00      0.00      0.00        11\n",
      "          47       0.84      0.36      0.51       209\n",
      "          48       0.49      0.53      0.51       201\n",
      "          49       0.40      0.20      0.26       202\n",
      "          50       0.67      0.06      0.11       206\n",
      "          51       0.00      0.00      0.00       206\n",
      "          52       0.00      0.00      0.00        20\n",
      "          53       0.77      0.23      0.35       118\n",
      "          54       0.62      0.38      0.47       185\n",
      "          55       0.97      0.18      0.31       196\n",
      "          56       0.45      0.92      0.61       181\n",
      "          57       0.62      0.55      0.58        96\n",
      "          58       0.00      0.00      0.00        34\n",
      "          59       0.49      0.59      0.54       121\n",
      "          60       0.00      0.00      0.00        93\n",
      "          61       0.73      0.04      0.08       184\n",
      "          62       1.00      0.15      0.26        74\n",
      "          63       0.05      0.89      0.09       230\n",
      "          64       1.00      0.16      0.28       141\n",
      "          65       0.25      0.02      0.03        58\n",
      "          66       0.28      0.59      0.38       202\n",
      "          67       0.88      0.10      0.18       206\n",
      "          68       0.00      0.00      0.00        37\n",
      "          69       0.78      0.77      0.78       194\n",
      "          70       0.86      0.30      0.44       202\n",
      "          71       0.34      0.64      0.44       210\n",
      "          72       0.95      0.65      0.77       188\n",
      "          73       0.50      0.64      0.56       196\n",
      "          74       0.94      0.08      0.15       205\n",
      "          75       0.90      0.10      0.18       180\n",
      "          76       0.70      0.31      0.43       197\n",
      "          77       0.82      0.30      0.44       119\n",
      "          78       0.29      0.23      0.25       190\n",
      "          79       1.00      0.04      0.07       187\n",
      "          80       0.75      0.04      0.07        77\n",
      "          81       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.27     13528\n",
      "   macro avg       0.52      0.24      0.24     13528\n",
      "weighted avg       0.57      0.27      0.26     13528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\Users\\Yunao\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "    \n",
    "train_start = time.time()\n",
    "sgd_classifier = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "traing_time = (time.time() - train_start)\n",
    "    \n",
    "predict_start= time.time()\n",
    "y_pred = sgd_classifier.predict(X_test)\n",
    "predict_time = (time.time() - predict_start)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['GD',traing_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>training duration(ms)</th>\n",
       "      <th>predicting duration(ms)</th>\n",
       "      <th>accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>13945.00</td>\n",
       "      <td>303088.00</td>\n",
       "      <td>44.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>886617.00</td>\n",
       "      <td>247318.00</td>\n",
       "      <td>51.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>14.02</td>\n",
       "      <td>372.07</td>\n",
       "      <td>44.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.50</td>\n",
       "      <td>28.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.04</td>\n",
       "      <td>76.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.81</td>\n",
       "      <td>19.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GD</td>\n",
       "      <td>10.39</td>\n",
       "      <td>0.06</td>\n",
       "      <td>26.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ensemble1</td>\n",
       "      <td>823850.00</td>\n",
       "      <td>654388.00</td>\n",
       "      <td>63.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  training duration(ms)  predicting duration(ms)  accuracy score\n",
       "0        KNN               13945.00                303088.00           44.63\n",
       "1        SVM              886617.00                247318.00           51.63\n",
       "2        KNN                  14.02                   372.07           44.63\n",
       "3         NB                   0.43                     5.50           28.97\n",
       "4         DT                   5.54                     0.04           76.35\n",
       "5         RF                   2.47                     1.81           19.83\n",
       "6         GD                  10.39                     0.06           26.92\n",
       "7  ensemble1              823850.00                654388.00           63.97"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_df = pd.DataFrame(performance_result, columns =evaluation_col)\n",
    "eva_df = eva_df.round(2)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.95      0.46       208\n",
      "           1       0.33      0.83      0.47       213\n",
      "           2       0.38      0.85      0.52       211\n",
      "           3       0.25      0.43      0.32       201\n",
      "           4       0.20      0.63      0.30       214\n",
      "           5       0.45      0.96      0.61       194\n",
      "           6       0.57      0.66      0.61       209\n",
      "           7       0.33      0.59      0.42       197\n",
      "           8       0.37      0.33      0.35       184\n",
      "           9       0.45      0.53      0.48       190\n",
      "          10       0.44      0.36      0.40       194\n",
      "          11       0.53      0.56      0.54       214\n",
      "          12       0.69      0.57      0.62       210\n",
      "          13       0.56      0.48      0.51       186\n",
      "          14       0.64      0.51      0.57       188\n",
      "          15       0.48      0.48      0.48       190\n",
      "          16       0.27      0.76      0.40       191\n",
      "          17       0.55      0.44      0.49       180\n",
      "          18       0.59      0.65      0.62       211\n",
      "          19       1.00      0.41      0.58        32\n",
      "          20       0.79      0.49      0.60       197\n",
      "          21       0.67      0.67      0.67       214\n",
      "          22       0.83      0.81      0.82       213\n",
      "          23       0.75      0.49      0.59       204\n",
      "          24       0.69      0.62      0.66       201\n",
      "          25       0.73      0.69      0.71       199\n",
      "          26       0.63      0.44      0.51       218\n",
      "          27       0.68      0.36      0.47       189\n",
      "          28       0.69      0.73      0.71       165\n",
      "          29       0.81      0.87      0.83       172\n",
      "          30       0.83      0.70      0.76       211\n",
      "          31       0.55      0.67      0.60       196\n",
      "          32       0.73      0.33      0.45       212\n",
      "          33       0.87      0.88      0.88       190\n",
      "          34       0.94      0.85      0.89       193\n",
      "          35       0.86      0.48      0.62       196\n",
      "          36       0.87      0.73      0.80       168\n",
      "          37       0.93      0.70      0.80       207\n",
      "          38       1.00      0.50      0.67         4\n",
      "          39       0.63      0.45      0.53       196\n",
      "          40       1.00      0.90      0.95        10\n",
      "          41       0.40      0.09      0.14        46\n",
      "          42       0.98      0.56      0.71        84\n",
      "          43       0.97      0.76      0.85       139\n",
      "          44       0.91      0.58      0.71        53\n",
      "          45       0.77      0.76      0.76       210\n",
      "          46       0.83      0.45      0.59        11\n",
      "          47       0.89      0.73      0.80       209\n",
      "          48       0.82      0.80      0.81       201\n",
      "          49       0.76      0.62      0.69       202\n",
      "          50       0.85      0.54      0.66       206\n",
      "          51       0.80      0.56      0.66       206\n",
      "          52       1.00      0.75      0.86        20\n",
      "          53       0.88      0.93      0.91       118\n",
      "          54       0.97      0.67      0.79       185\n",
      "          55       0.95      0.81      0.87       196\n",
      "          56       0.97      0.93      0.95       181\n",
      "          57       0.98      0.65      0.78        96\n",
      "          58       1.00      0.41      0.58        34\n",
      "          59       1.00      0.70      0.83       121\n",
      "          60       0.90      0.60      0.72        93\n",
      "          61       0.85      0.51      0.63       184\n",
      "          62       1.00      0.45      0.62        74\n",
      "          63       0.96      0.50      0.65       230\n",
      "          64       0.98      0.89      0.93       141\n",
      "          65       0.83      0.43      0.57        58\n",
      "          66       0.91      0.52      0.66       202\n",
      "          67       0.93      0.86      0.89       206\n",
      "          68       1.00      0.59      0.75        37\n",
      "          69       0.95      0.89      0.92       194\n",
      "          70       0.79      0.93      0.85       202\n",
      "          71       0.97      0.48      0.64       210\n",
      "          72       0.98      0.88      0.92       188\n",
      "          73       0.98      0.65      0.78       196\n",
      "          74       0.92      0.76      0.83       205\n",
      "          75       0.98      0.47      0.64       180\n",
      "          76       0.97      0.59      0.73       197\n",
      "          77       0.98      0.53      0.69       119\n",
      "          78       0.94      0.33      0.48       190\n",
      "          79       0.97      0.68      0.80       187\n",
      "          80       1.00      0.74      0.85        77\n",
      "          81       1.00      0.71      0.83        68\n",
      "\n",
      "    accuracy                           0.64     13528\n",
      "   macro avg       0.77      0.63      0.67     13528\n",
      "weighted avg       0.74      0.64      0.66     13528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "eclf1 = VotingClassifier(estimators=[('knn', KNN_classifier), ('DT', dt_classifier), ('svm', svm_classifier)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "traning_time = int((time.time() - train_start)*1000)\n",
    "\n",
    "predict_start= time.time()\n",
    "y_pred=eclf1.predict(X_test)\n",
    "predict_time = int((time.time() - predict_start)*1000)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['ensemble1',traning_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier=svm.SVC(probability=True)\n",
    "train_start = time.time()\n",
    "eclf2 = VotingClassifier(estimators=[('knn', KNN_classifier), ('DT', dt_classifier), ('svm', svm_classifier)], voting='soft')\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "traning_time = int((time.time() - train_start)*1000)\n",
    "\n",
    "predict_start= time.time()\n",
    "y_pred=eclf2.predict(X_test)\n",
    "predict_time = int((time.time() - predict_start)*1000)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['ensemble2',traning_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.time()\n",
    "eclf3 = VotingClassifier(estimators=[('knn', KNN_classifier), ('DT', dt_classifier), ('svm', svm_classifier)], voting='soft', weights=[1,1,2],flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X_train, y_train)\n",
    "traning_time = int((time.time() - train_start)*1000)\n",
    "\n",
    "predict_start= time.time()\n",
    "y_pred=eclf3.predict(X_test)\n",
    "predict_time = int((time.time() - predict_start)*1000)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['ensemble3',traning_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier=svm.SVC(probability=True)\n",
    "train_start = time.time()\n",
    "eclf4 = VotingClassifier(estimators=[('knn', KNN_classifier), ('DT', dt_classifier), ('svm', svm_classifier)], voting='soft', weights=[1,2,1],flatten_transform=True)\n",
    "eclf4 = eclf4.fit(X_train, y_train)\n",
    "traning_time = int((time.time() - train_start)*1000)\n",
    "\n",
    "predict_start= time.time()\n",
    "y_pred=eclf4.predict(X_test)\n",
    "predict_time = int((time.time() - predict_start)*1000)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['ensemble4',traning_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier=svm.SVC(probability=True)\n",
    "train_start = time.time()\n",
    "eclf5 = VotingClassifier(estimators=[('knn', KNN_classifier), ('DT', dt_classifier), ('svm', svm_classifier)], voting='soft', weights=[2,1,1],flatten_transform=True)\n",
    "eclf5 = eclf5.fit(X_train, y_train)\n",
    "traning_time = int((time.time() - train_start)*1000)\n",
    "\n",
    "predict_start= time.time()\n",
    "y_pred=eclf5.predict(X_test)\n",
    "predict_time = int((time.time() - predict_start)*1000)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "performance_result.append(['ensemble5',traning_time,predict_time,accuracy])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
